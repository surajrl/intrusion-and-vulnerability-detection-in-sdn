from pox.core import core
import pox.log.color

from scapy.packet import Packet as ScapyPacket
from scapy.sendrecv import sniff

from sklearn import preprocessing

import pandas as pd
import numpy as np

from flowmeter import constants
from flowmeter.v2flow import v2Flow
from flowmeter.utils import PacketDirection, get_packet_flow_key

from joblib import load


log = core.getLogger()

labels = [
    'Benign',
    'Bot',
    'DDoS',
    'DoS_GoldenEye',
    'DoS_Hulk',
    'DoS_SlowHTTPTest',
    'DoS_Slowloris',
    'FTP_Patator',
    'Heartbleed',
    'Infiltration',
    'Port_Scan',
    'SSH_Patator', 
    'Web_Attack_Brute_Force',
    'Web_Attack_SQL_Injection',
    'Web_Attack_XSS'
    ]

class POX_IDS(object):
  """
  A POX_IDS object is created for each switch that connects.
  A connection object for that switch is passed to the __init__ function.
  """
  def __init__ (self, connection):
    # Keep track of the connection to the switch so that we can send it messages.
    self.connection = connection

    # Bind our event listeners to the switch.
    connection.addListeners(self)

    # Track which ethernet address is on which switch port (keys are MACs, values are ports).
    self.mac_to_port = {}

    # Track all the network flows.
    self.flows = {}

    # Track the number of packets received.
    self.packets_count = 0

    # Load ML classifier.
    self.clf = load('/home/suraj/intrusion-and-vulnerability-detection-in-sdn/ml/dt_model.joblib')
    log.info('Machine learning model loaded')
    # Load the normalization scaler.
    train_filepath = '/home/suraj/intrusion-and-vulnerability-detection-in-sdn/ml/dataset/cleaned_dataset_train.csv'
    train_df = pd.read_csv(train_filepath, skipinitialspace=True)
    log.info('Train dataset loaded')
    x_train = train_df.drop(train_df.columns[-1], axis=1) # drop the last colum (i.e. labels)
    log.info('Train dataset ready')
    self.scaler = preprocessing.StandardScaler()
    self.scaler.fit(x_train)
    log.info('Scaler loaded')
    # Load the required features.
    features_filepath = '/home/suraj/intrusion-and-vulnerability-detection-in-sdn/ml/features.txt'
    self.features = []
    with open(features_filepath, 'r') as file:
      for line in file:
        self.features.append(str(line.strip()))

    # Start sniffing packets.
    sniff(prn=self.handle_packet)


  def handle_packet(self, packet: ScapyPacket):
    """
    Handles a packet captured from Scapy.
    """


    count = 0
    # Start by assuming the packet is in the forward direction.
    direction = PacketDirection.FORWARD

    # Check if the flow exists.
    try:
      packet_flow_key = get_packet_flow_key(packet, direction)
      flow = self.flows.get((packet_flow_key, count))
    except Exception:
      log.info(f'Scapy Packet {self.packets_count} -> Not a TCP or UDP packet -> {packet}')
      return
  
    log.info(f'Scapy Packet {self.packets_count} -> {packet}')
    
    self.packets_count += 1

    # If there is no forward flow with a count of 0, check if there is one of it in reverse.
    if flow is None:
      direction = PacketDirection.REVERSE
      packet_flow_key = get_packet_flow_key(packet, direction)
      flow = self.flows.get((packet_flow_key, count))
    
    # Create a new flow.
    if flow is None:
      # If no flow exists
      direction = PacketDirection.FORWARD
      flow = v2Flow(packet, direction)
      packet_flow_key = get_packet_flow_key(packet, direction)
      self.flows[(packet_flow_key, count)] = flow
    
    elif (packet.time - flow.latest_timestamp) > constants.EXPIRED_UPDATE:
       # If the packet exists in the flow but the packet is sent after too much of a delay, then it is part of a new flow.
       expired =  constants.EXPIRED_UPDATE
       while (packet.time - flow.latest_timestamp) > expired:
          count += 1
          expired +=  constants.EXPIRED_UPDATE
          flow = self.flows.get((packet_flow_key, count))

          if flow is None:
             flow = v2Flow(packet, direction)
             self.flows[(packet_flow_key, count)] = flow
             break
          
    elif 'F' in packet.flags:
       # If it has a FIN flag then early collect flow.
       flow.add_packet(packet, direction)
       self.garbage_collect(packet.time)
       return

    flow.add_packet(packet, direction)
    
    # Extract only the values of the features required by the model.
    flow_data = flow.get_data()
    features_values = []
    for k, v in flow_data.items():
      if k in self.features:
          features_values.append(v)

    # Normalize the values.
    features_values_normalized = self.scaler.transform(features_values)
    # Classify
    prediction = self.clf.predict(X=np.array(features_values_normalized).reshape(1, -1))
    log.info(f'Prediction: {labels[prediction[0]]}')

    # If the number of packets collected reaches GARBAGE_COLLECT_PACKETS or the flow is lasting too long, collect flow.
    if self.packets_count %  constants.GARBAGE_COLLECT_PACKETS == 0 or flow.duration > 120:
            self.garbage_collect(packet.time)
      
  def garbage_collect(self, latest_time) -> None:
    # TODO: Garbage Collection / Feature Extraction should have a separate thread
    log.info(f"Garbage Collection Began. Flows = {len(self.flows)}")

    for k in list(self.flows.keys()):
        flow = self.flows.get(k)

        if (
            latest_time is not None
            and latest_time - flow.latest_timestamp <  constants.EXPIRED_UPDATE
            and flow.duration < 90
        ):
            continue

        # TODO: Save into a CSV file
        log.info(flow.get_data())
        del self.flows[k]
    
    log.info(f"Garbage Collection Finished. Flows = {len(self.flows)}")


def launch ():
  """
  Starts the component
  """
  
  # Logger.
  pox.log.color.launch()
  pox.log.launch(format='[@@@bold%(levelname)s@@@reset][@@@bold%(asctime)s@@@reset][@@@bold%(filename)s@@@reset]: @@@bold%(message)s@@@normal')
  
  def start_switch(event):
    log.info('Controlling %s' % (event.connection,))
    POX_IDS(event.connection)
  
  # Start connection with the switch.
  core.openflow.addListenerByName('ConnectionUp', start_switch)
