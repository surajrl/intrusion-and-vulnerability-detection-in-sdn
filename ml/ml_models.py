import pandas as pd
from sklearn import preprocessing, neighbors, tree
from sklearn.metrics import classification_report, confusion_matrix
from matplotlib import pyplot as plt
import seaborn as sns
import time
import pickle

"""
Load dataset.
"""

train_filepath = 'C:/Users/Suraj/OneDrive - University of Surrey/Third Year/Year 3 Project (EEE3017)/Dataset/cleaned_dataset_train.csv'
test_filepath = 'C:/Users/Suraj/OneDrive - University of Surrey/Third Year/Year 3 Project (EEE3017)/Dataset/cleaned_dataset_test.csv'
train_df = pd.read_csv(train_filepath, skipinitialspace=True)
test_df = pd.read_csv(test_filepath, skipinitialspace=True)

x_train = train_df.drop(train_df.columns[-1], axis=1) # drop the last colum (i.e. labels)
y_train = train_df[train_df.columns[-1]] # get the last column
x_test = test_df.drop(test_df.columns[-1], axis=1)
y_test = test_df[test_df.columns[-1]]

# Save the features
features = test_df.columns.values.tolist()[0: -1]
pickle.dump(features, open('features.pkl', 'wb'))

"""
Normalization.
"""

scaler = preprocessing.StandardScaler()
scaler.fit(x_train)
# Save the scaler
pickle.dump(scaler, open('scaler.pkl', 'wb'))
# Scale the data
x_train = scaler.transform(x_train.values)
x_test = scaler.transform(x_test)

clf = tree.DecisionTreeClassifier(random_state=1, criterion='entropy', max_depth=10, splitter='random')
# clf = neighbors.KNeighborsClassifier(n_neighbors=15, p=2, n_jobs=-1)

"""
Train.
"""
train_start = time.perf_counter()
clf.fit(X=x_train, y=y_train)
train_end = time.perf_counter()

"""
Test.
"""
test_start = time.perf_counter()
y_pred = clf.predict(X=x_test)
test_end = time.perf_counter()

# Save model
pickle.dump(clf, open('dt_model.pkl', 'wb'))

"""
Results.
"""

labels = [
    'Benign',
    'Bot',
    'DDoS',
    'DoS_GoldenEye',
    'DoS_Hulk',
    'DoS_SlowHTTPTest',
    'DoS_Slowloris',
    'FTP_Patator',
    'Heartbleed',
    'Infiltration',
    'Port_Scan',
    'SSH_Patator', 
    'Web_Attack_Brute_Force',
    'Web_Attack_SQL_Injection',
    'Web_Attack_XSS'
    ]

# intialize empty dictionaries
tp, fn, fp, tn = {}, {}, {}, {}
for label in labels:
    tp[label] = 0
    fn[label] = 0
    fp[label] = 0
    tn[label] = 0

for true, pred in zip(y_test, y_pred):
    true = labels[true]
    pred = labels[pred]

    if pred == true:
        tp[true] += 1
        for label in labels:
            if label != true:
                tn[true] += 1
    
    else:
        fp[pred] += 1
        fn[true] += 1

for label in labels:
    try:
        precision = tp[label] / (tp[label] + fp[label])
        recall = tp[label] / (tp[label] + fn[label])
        fpr = fp[label] / (fp[label] + tn[label])
    except ZeroDivisionError:
        pass

    print(f'Traffic type: {label}')
    print(f'Precision: {precision:.4f}') 
    print(f'Recall: {recall:.4f}')
    print(f'False Positive Rate: {fpr}')
    print()
    
# precision, recall, f1-score for each class
report = classification_report(y_true=y_test, y_pred=y_pred, digits=4, zero_division=0, target_names=labels)
cm = confusion_matrix(y_true=y_test, y_pred=y_pred, normalize='true')

print(f'Training time: {(train_end-train_start):.4f} seconds')
print(f'Testing time: {(test_end-test_start):.4f} seconds\n')
print(report)

plt.figure(figsize=(15,15))
sns.heatmap(cm, annot=True, fmt='.4f', cmap='viridis', square=True, xticklabels=labels, yticklabels=labels, cbar=False)
plt.ylabel('True Labels')
plt.xlabel('Predicted Labels')