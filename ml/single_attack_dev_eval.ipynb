{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "TIME_BASED_FEATURES = [\n",
    "    \"bidirectional_first_seen_ms\",\n",
    "    \"bidirectional_last_seen_ms\",\n",
    "    \"src2dst_first_seen_ms\",\n",
    "    \"src2dst_last_seen_ms\",\n",
    "    \"dst2src_first_seen_ms\",\n",
    "    \"dst2src_last_seen_ms\",\n",
    "]\n",
    "\n",
    "ARCHITECTURE_BASED_FEATURES = [\n",
    "    \"id\",\n",
    "    \"expiration_id\",\n",
    "    \"src_ip\",\n",
    "    \"src_mac\",\n",
    "    \"src_oui\",\n",
    "    \"src_port\",\n",
    "    \"dst_ip\",\n",
    "    \"dst_mac\",\n",
    "    \"dst_oui\",\n",
    "    \"dst_port\",\n",
    "    \"protocol\",\n",
    "    \"ip_version\",\n",
    "    \"vlan_id\",\n",
    "]\n",
    "\n",
    "\"\"\"\n",
    "LABEL.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def label_dataset(df: pd.DataFrame, label: str) -> pd.DataFrame:\n",
    "    attack_ip = \"172.16.0.1\"\n",
    "    victim_ip = \"192.168.10.50\"\n",
    "\n",
    "    # Create label column.\n",
    "    df[\"label\"] = \"benign\"\n",
    "\n",
    "    # Set to True those records with the attack source IP address and victim destination IP address.\n",
    "    mask = pd.DataFrame(True, index=df.index, columns=[df.columns[0]]).squeeze()\n",
    "    mask &= df[\"src_ip\"] == attack_ip\n",
    "    mask &= df[\"dst_ip\"] == victim_ip\n",
    "\n",
    "    df[\"label\"] = df[\"label\"].mask(mask, label)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "PREPROCESS.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def preprocess_dataset(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Drop bias features/columns.\n",
    "    df = df.drop(\n",
    "        columns=TIME_BASED_FEATURES + ARCHITECTURE_BASED_FEATURES, errors=\"ignore\"\n",
    "    )\n",
    "\n",
    "    # Label-encoding to replace categorical values with numerical.\n",
    "    labels = df[\"label\"].values.reshape(-1, 1)\n",
    "    encoder = LabelEncoder()\n",
    "    encoded_labels = encoder.fit_transform(\n",
    "        labels.reshape(\n",
    "            -1,\n",
    "        )\n",
    "    )\n",
    "    df[\"label\"] = encoded_labels\n",
    "    print(\"\\nEncoding:\")\n",
    "    for i, label in enumerate(encoder.classes_):\n",
    "        print(f\"{i}: {label}\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DoS Slowloris (5sec flow active timeout) shape: (57291, 76)\n",
      "DoS Slowhttptest (5sec flow active timeout) shape: (62767, 76)\n",
      "DoS Hulk (5sec flow active timeout) shape: (197559, 76)\n",
      "DoS GoldenEye (5sec flow active timeout) shape: (38490, 76)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dos_slowloris_df = pd.read_csv(\"./dataset/dos_slowloris.csv\")\n",
    "dos_slowhttptest_df = pd.read_csv(\"./dataset/dos_slowhttptest.csv\")\n",
    "dos_hulk_df = pd.read_csv(\"./dataset/dos_hulk.csv\")\n",
    "dos_goldeneye_df = pd.read_csv(\"./dataset/dos_goldeneye.csv\")\n",
    "\n",
    "print(f\"DoS Slowloris (5sec flow active timeout) shape: {dos_slowloris_df.shape}\")\n",
    "print(f\"DoS Slowhttptest (5sec flow active timeout) shape: {dos_slowhttptest_df.shape}\")\n",
    "print(f\"DoS Hulk (5sec flow active timeout) shape: {dos_hulk_df.shape}\")\n",
    "print(f\"DoS GoldenEye (5sec flow active timeout) shape: {dos_goldeneye_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Encoding:\n",
      "0: benign\n",
      "1: dos_slowloris\n",
      "\n",
      "Encoding:\n",
      "0: benign\n",
      "1: dos_slowhttptest\n",
      "\n",
      "Encoding:\n",
      "0: benign\n",
      "1: dos_hulk\n",
      "\n",
      "Encoding:\n",
      "0: benign\n",
      "1: dos_goldeneye\n",
      "DoS Slowloris\n",
      "label\n",
      "0    41049\n",
      "1    16242\n",
      "Name: count, dtype: int64\n",
      "\n",
      "DoS Slowhttptest\n",
      "label\n",
      "0    43330\n",
      "1    19437\n",
      "Name: count, dtype: int64\n",
      "\n",
      "DoS Hulk\n",
      "label\n",
      "1    161263\n",
      "0     36296\n",
      "Name: count, dtype: int64\n",
      "\n",
      "DoS GoldenEye\n",
      "label\n",
      "0    27797\n",
      "1    10693\n",
      "Name: count, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labelled_dos_slowloris_df = label_dataset(dos_slowloris_df, \"dos_slowloris\")\n",
    "labelled_dos_slowhttptest_df = label_dataset(dos_slowhttptest_df, \"dos_slowhttptest\")\n",
    "labelled_dos_hulk_df = label_dataset(dos_hulk_df, \"dos_hulk\")\n",
    "labelled_dos_goldeneye_df = label_dataset(dos_goldeneye_df, \"dos_goldeneye\")\n",
    "\n",
    "preprocessed_dos_slowloris_df = preprocess_dataset(labelled_dos_slowloris_df)\n",
    "preprocessed_dos_slowhttptest_df = preprocess_dataset(labelled_dos_slowhttptest_df)\n",
    "preprocessed_dos_hulk_df = preprocess_dataset(labelled_dos_hulk_df)\n",
    "preprocessed_dos_goldeneye_df = preprocess_dataset(labelled_dos_goldeneye_df)\n",
    "\n",
    "print(\"DoS Slowloris\")\n",
    "print(preprocessed_dos_slowloris_df[\"label\"].value_counts())\n",
    "print()\n",
    "print(\"DoS Slowhttptest\")\n",
    "print(preprocessed_dos_slowhttptest_df[\"label\"].value_counts())\n",
    "print()\n",
    "print(\"DoS Hulk\")\n",
    "print(preprocessed_dos_hulk_df[\"label\"].value_counts())\n",
    "print()\n",
    "print(\"DoS GoldenEye\")\n",
    "print(preprocessed_dos_goldeneye_df[\"label\"].value_counts())\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TRAIN AND TEST MODEL.\n",
    "\"\"\"\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from imbens.metrics import classification_report_imbalanced\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "\n",
    "def train_and_test(\n",
    "    df: pd.DataFrame, name: str, class_labels: list, show_results: bool, save: bool\n",
    "):\n",
    "    # Remove the labels on X and mantain on y.\n",
    "    X = df.drop(df.columns[-1], axis=1)\n",
    "    y = df[df.columns[-1]]\n",
    "\n",
    "    # Split dataset to training and testing.\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.35, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    # Scale.\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "    scaler.fit(X_train.values)\n",
    "    X_train_scaled = scaler.transform(X_train.values)\n",
    "    X_test_scaled = scaler.transform(X_test.values)\n",
    "\n",
    "    # Classifier.\n",
    "    clf = tree.DecisionTreeClassifier(\n",
    "        criterion=\"gini\", max_depth=None, min_samples_split=2, min_samples_leaf=1\n",
    "    )\n",
    "\n",
    "    # Train.\n",
    "    clf.fit(X=X_train_scaled, y=y_train)\n",
    "    # Test.\n",
    "    y_pred = clf.predict(X=X_test_scaled)\n",
    "\n",
    "    acc = accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "    report_imbens = classification_report_imbalanced(\n",
    "        y_true=y_test, y_pred=y_pred, digits=4\n",
    "    )\n",
    "    cm_normalized = confusion_matrix(y_test, y_pred, normalize=\"true\")\n",
    "\n",
    "    # Display test evaluation.\n",
    "    if show_results:\n",
    "        print(acc)\n",
    "        print(report_imbens)\n",
    "        plt.figure(figsize=(15, 15))\n",
    "        sns.heatmap(\n",
    "            cm_normalized,\n",
    "            annot=True,\n",
    "            fmt=\".4f\",\n",
    "            cmap=\"viridis\",\n",
    "            square=True,\n",
    "            xticklabels=class_labels,\n",
    "            yticklabels=class_labels,\n",
    "        )\n",
    "        plt.xlabel(\"Predicted Labels\")\n",
    "        plt.ylabel(\"True Labels\")\n",
    "\n",
    "    # Save scaler and model.\n",
    "    if save:\n",
    "        pickle.dump(scaler, open(f\"./saved/{name}_scaler.pkl\", \"wb\"))\n",
    "        pickle.dump(clf, open(f\"./saved/{name}_model.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_test(\n",
    "    preprocessed_dos_slowloris_df,\n",
    "    \"dos_slowloris\",\n",
    "    [\"Benign\", \"Dos Slowloris\"],\n",
    "    show_results=False,\n",
    "    save=False,\n",
    ")\n",
    "\n",
    "\n",
    "train_and_test(\n",
    "    preprocessed_dos_slowhttptest_df,\n",
    "    \"dos_slowhttptest\",\n",
    "    [\"Benign\", \"Dos Slowhttptest\"],\n",
    "    show_results=False,\n",
    "    save=False,\n",
    ")\n",
    "\n",
    "\n",
    "train_and_test(\n",
    "    preprocessed_dos_hulk_df,\n",
    "    \"dos_hulk\",\n",
    "    [\"Benign\", \"Dos Hulk\"],\n",
    "    show_results=False,\n",
    "    save=False,\n",
    ")\n",
    "\n",
    "\n",
    "train_and_test(\n",
    "    preprocessed_dos_goldeneye_df,\n",
    "    \"dos_goldeneye\",\n",
    "    [\"Benign\", \"Dos GoldenEye\"],\n",
    "    show_results=False,\n",
    "    save=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "\n",
    "def evaluate_live_performance(\n",
    "    model_name, evaluation_features_filepath, prediction_features_filepath\n",
    "):\n",
    "    evaluation_features_df = pd.read_csv(\n",
    "        evaluation_features_filepath, skipinitialspace=True\n",
    "    )\n",
    "    prediction_features_df = pd.read_csv(\n",
    "        prediction_features_filepath, skipinitialspace=True\n",
    "    )\n",
    "\n",
    "    # Label the live features.\n",
    "    labelled_evaluation_features_df = label_dataset(evaluation_features_df, model_name)\n",
    "\n",
    "    y_true = labelled_evaluation_features_df[\"label\"]\n",
    "    y_pred = prediction_features_df[\"label\"]\n",
    "    accuracy = accuracy_score(\n",
    "        y_true=y_true,\n",
    "        y_pred=y_pred,\n",
    "    )\n",
    "    cm_normalized = confusion_matrix(y_true=y_true, y_pred=y_pred, normalize=\"true\")\n",
    "\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    sns.heatmap(\n",
    "        cm_normalized,\n",
    "        annot=True,\n",
    "        fmt=\".4f\",\n",
    "        cmap=\"viridis\",\n",
    "        square=True,\n",
    "        xticklabels=[\"Benign\", f\"{model_name}\"],\n",
    "        yticklabels=[\"Benign\", f\"{model_name}\"],\n",
    "    )\n",
    "    plt.xlabel(\"Predicted Labels\")\n",
    "    plt.ylabel(\"True Labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [37122, 32746]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m evaluation_features_filepath \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../flow_extraction/evaluation_features.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      2\u001b[0m prediction_features_filepath \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../flow_extraction/prediction_features.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 4\u001b[0m \u001b[43mevaluate_live_performance\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdos_goldeneye\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevaluation_features_filepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction_features_filepath\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[6], line 20\u001b[0m, in \u001b[0;36mevaluate_live_performance\u001b[1;34m(model_name, evaluation_features_filepath, prediction_features_filepath)\u001b[0m\n\u001b[0;32m     18\u001b[0m y_true \u001b[38;5;241m=\u001b[39m labelled_evaluation_features_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     19\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m prediction_features_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m---> 20\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m \u001b[43maccuracy_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_true\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_pred\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m cm_normalized \u001b[38;5;241m=\u001b[39m confusion_matrix(y_true\u001b[38;5;241m=\u001b[39my_true, y_pred\u001b[38;5;241m=\u001b[39my_pred, normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrue\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Suraj\\miniconda3\\envs\\year3project\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Suraj\\miniconda3\\envs\\year3project\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:213\u001b[0m, in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Accuracy classification score.\u001b[39;00m\n\u001b[0;32m    148\u001b[0m \n\u001b[0;32m    149\u001b[0m \u001b[38;5;124;03mIn multilabel classification, this function computes subset accuracy:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[38;5;124;03m0.5\u001b[39;00m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;66;03m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[1;32m--> 213\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\Suraj\\miniconda3\\envs\\year3project\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:85\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_targets\u001b[39m(y_true, y_pred):\n\u001b[0;32m     59\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \n\u001b[0;32m     61\u001b[0m \u001b[38;5;124;03m    This converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;124;03m    y_pred : array or indicator matrix\u001b[39;00m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 85\u001b[0m     \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     86\u001b[0m     type_true \u001b[38;5;241m=\u001b[39m type_of_target(y_true, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     87\u001b[0m     type_pred \u001b[38;5;241m=\u001b[39m type_of_target(y_pred, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Suraj\\miniconda3\\envs\\year3project\\Lib\\site-packages\\sklearn\\utils\\validation.py:457\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    455\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 457\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    458\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    459\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    460\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [37122, 32746]"
     ]
    }
   ],
   "source": [
    "evaluation_features_filepath = \"../flow_extraction/evaluation_features.csv\"\n",
    "prediction_features_filepath = \"../flow_extraction/prediction_features.csv\"\n",
    "\n",
    "evaluate_live_performance(\n",
    "    \"dos_goldeneye\", evaluation_features_filepath, prediction_features_filepath\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "year3project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
