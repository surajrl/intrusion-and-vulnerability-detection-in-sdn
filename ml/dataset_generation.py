from nfstream import NFStreamer

# Linux
monday_pcap_filepath = "/home/suraj/pcaps/Monday-WorkingHours.pcap"
tuesday_pcap_filepath = "/home/suraj/pcaps/Tuesday-WorkingHours.pcap"
wednesday_pcap_filepath = "/home/suraj/pcaps/Wednesday-WorkingHours.pcap"
friday_pcap_filepath = "/home/suraj/pcaps/Friday-WorkingHours.pcap"

all_pcaps = {
    "Monday-WorkingHours": monday_pcap_filepath,
    "Tuesday-WorkingHours": tuesday_pcap_filepath,
    "Wednesday-WorkingHours": wednesday_pcap_filepath,
    "Friday-WorkingHours": friday_pcap_filepath,
}

for filename, filepath in all_pcaps.items():
    my_streamer = NFStreamer(
        source=filepath,
        decode_tunnels=False,  # Disable GTP/CAPWAP/TZSP tunnels decoding.
        bpf_filter=None,
        promiscuous_mode=True,  # Enable promiscuous capture mode.
        snapshot_length=1536,  # Control packet slicing size (truncation) in bytes.
        idle_timeout=120,  # Flows that are idle (no packets received) for more than 120 seconds are expired.
        active_timeout=5,  # Flows that are active for more than 5 seconds are expired.
        accounting_mode=3,  # Accounting mode that will be used to report bytes related features, 3: payload.
        udps=None,
        n_dissections=0,  # Disable L7 visibility feature.
        statistical_analysis=True,  # Enable post-mortem flow statistical analysis.
        splt_analysis=0,
        n_meters=0,
        max_nflows=0,
        performance_report=0,
        system_visibility_mode=0,
        system_visibility_poll_ms=100,
    )

    # Generate CSV file containing the flows and features.
    output_filepath = f"/home/suraj/{filename}.csv"
    total_flows_count = my_streamer.to_csv(output_filepath)
