{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Label encoding**\n",
    "\n",
    "- **benign: 0**\n",
    "- **bot: 1**\n",
    "- **ddos: 2**\n",
    "- **dos_goldeneye: 3**\n",
    "- **dos_hulk: 4**\n",
    "- **dos_slowhttptest: 5**\n",
    "- **dos_slowloris: 6**\n",
    "- **ftp_patator: 7**\n",
    "- **portscan: 8**\n",
    "- **ssh_patator: 9**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cicids2017_df = pd.read_csv(\"../dataset/cicids2017-preprocessed.csv\", skipinitialspace=True)\n",
    "cicids2017_resampled_df = pd.read_csv(\"../dataset/cicids2017-resampled.csv\", skipinitialspace=True)\n",
    "\n",
    "print(f\"CIC-IDS 2017: {cicids2017_df.shape}\")\n",
    "print(cicids2017_df[\"label\"].value_counts())\n",
    "print(f\"CIC-IDS 2017 (Resampled): {cicids2017_resampled_df.shape}\")\n",
    "print(cicids2017_resampled_df[\"label\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Module 2 - Anomaly Detection using CL K-Means**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cicids2017_resampled_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normalize dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "feature_columns = df.drop(columns=[\"label\"])\n",
    "label_column_data = df[\"label\"]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "normalized_feature_columns = pd.DataFrame(scaler.fit_transform(feature_columns), columns=feature_columns.columns)\n",
    "normalized_df = pd.concat([normalized_feature_columns, label_column_data], axis=1)\n",
    "normalized_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resample Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Retain the minority class instances and sample the majority class instances\n",
    "minority_class_df = df[(df['label'] == 6) | (df['label'] == 1) | (df['label'] == 8) | (df['label'] == 5) | (df['label'] == 7) | (df['label'] == 3)]\n",
    "majority_class_df = df.drop(minority_class_df.index)\n",
    "\n",
    "X = majority_class_df.drop(['label'],axis=1) \n",
    "y = majority_class_df.iloc[:, -1].values.reshape(-1,1)\n",
    "y = np.ravel(y)\n",
    "\n",
    "# Use k-means to cluster the data samples and select a proportion of data from each cluster\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "kmeans = MiniBatchKMeans(n_clusters=1000, random_state=0).fit(X)\n",
    "\n",
    "majority_class_df['klabel'] = kmeans.labels_\n",
    "\n",
    "majority_class_df['klabel'].value_counts()\n",
    "\n",
    "cols = list(majority_class_df)\n",
    "cols.insert(38, cols.pop(cols.index('label')))\n",
    "majority_class_df = majority_class_df.loc[:, cols]\n",
    "\n",
    "def typicalSampling(group):\n",
    "    frac = 0.008\n",
    "    return group.sample(frac=frac)\n",
    "\n",
    "resampled_df = majority_class_df.groupby('klabel', group_keys=False).apply(typicalSampling)\n",
    "resampled_df = resampled_df.drop(['klabel'],axis=1)\n",
    "resampled_df = resampled_df._append(minority_class_df)\n",
    "\n",
    "print(resampled_df['label'].value_counts())\n",
    "resampled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = resampled_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNKNOWN_ATTACK_LABEL = 3\n",
    "\n",
    "# Remove a single attack (to be used as train set)\n",
    "without_unknown_attack_df = df[df[\"label\"] != UNKNOWN_ATTACK_LABEL]\n",
    "without_unknown_attack_df.loc[:, \"label\"] = without_unknown_attack_df[\"label\"].apply(lambda x: 0 if x == 0 else 1)\n",
    "\n",
    "# Preserve the unknown attack (to be used a test set)\n",
    "with_unknown_attack_df = df[df[\"label\"] == UNKNOWN_ATTACK_LABEL]\n",
    "with_unknown_attack_df.loc[:, \"label\"] = with_unknown_attack_df[\"label\"].apply(lambda x: 0 if x == 0 else 1)\n",
    "\n",
    "benign_df = without_unknown_attack_df[without_unknown_attack_df[\"label\"] == 0]\n",
    "# Randomly sample benign data\n",
    "benign_sample_df = benign_df.sample(\n",
    "    n=None,\n",
    "    frac=with_unknown_attack_df.shape[0] / benign_df.shape[0],\n",
    "    replace=False,\n",
    "    weights=None,\n",
    "    random_state=42,\n",
    ")\n",
    "# Mix it with unknown attack data\n",
    "with_unknown_attack_df = pd.concat([with_unknown_attack_df, benign_sample_df])\n",
    "\n",
    "# Add the test set to the end of the dataframe\n",
    "df = without_unknown_attack_df._append(with_unknown_attack_df)\n",
    "\n",
    "print(with_unknown_attack_df[\"label\"].value_counts())\n",
    "print(without_unknown_attack_df[\"label\"].value_counts())\n",
    "print(df[\"label\"].value_counts())\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Separate independent (X) and dependent (Y) variables**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[\"label\"]).values\n",
    "y = df[\"label\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature selection**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mutual information\n",
    "\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "importances = mutual_info_classif(X, y)\n",
    "features = df.drop(columns=[\"label\"]).columns\n",
    "\n",
    "# Calculate the sum of importance scores\n",
    "f_list = sorted(zip(map(lambda x: round(x, 4), importances), features), reverse=True)\n",
    "sum = 0\n",
    "fs = []\n",
    "for i in range(0, len(f_list)):\n",
    "    sum = sum + f_list[i][0]\n",
    "    fs.append(f_list[i][1])\n",
    "\n",
    "# Select the important features from top to bottom until the accumulated importance reaches 90%\n",
    "f_list2 = sorted(zip(map(lambda x: round(x, 4), importances/sum), features), reverse=True)\n",
    "sum_2 = 0\n",
    "featuers_selected = []\n",
    "for i in range(0, len(f_list2)):\n",
    "    sum_2 = sum_2 + f_list2[i][0]\n",
    "    featuers_selected.append(f_list2[i][1])\n",
    "    if sum_2 >= 0.9:\n",
    "        break     \n",
    "\n",
    "# Mantain only the selected features\n",
    "X_features_selection = df[featuers_selected].values\n",
    "X_features_selection.shape   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=10)\n",
    "pca.fit(X_features_selection)\n",
    "X_pca = pca.transform(X_features_selection)\n",
    "X_pca.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train and test split**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample containing benign and all attacks except the unknown\n",
    "X_train = X_pca[:len(without_unknown_attack_df)]\n",
    "y_train = y[:len(without_unknown_attack_df)]\n",
    "\n",
    "# Sample containing benign and only the unknown attack, as the model will be trained with benign and all attacks except for the unknown\n",
    "X_test = X_pca[len(without_unknown_attack_df):]\n",
    "y_test = y[len(without_unknown_attack_df):]\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(y_train).value_counts(), pd.Series(y_test).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Class-imbalance in train set**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(sampling_strategy=\"auto\")\n",
    "\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(pd.Series(y_train).value_counts())\n",
    "print(pd.Series(y_test).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model training and testing (unsupervised learning)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans , KMeans\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Cluster labelling k-means\n",
    "def cl_kmeans(X_train, X_test, y_train, y_test, n, b=100):\n",
    "    km_cluster = MiniBatchKMeans(n_clusters=n, batch_size=b, random_state=42)\n",
    "    result = km_cluster.fit_predict(X_train)\n",
    "    result2 = km_cluster.predict(X_test)\n",
    "\n",
    "    a = np.zeros(n)\n",
    "    b = np.zeros(n)\n",
    "    for v in range(0, n):\n",
    "        for i in range(0, len(y_train)):\n",
    "            if result[i] == v:\n",
    "                if y_train[i] == 1:\n",
    "                    a[v] = a[v] + 1\n",
    "                else:\n",
    "                    b[v] = b[v] + 1\n",
    "    list1 = []\n",
    "    list2 = []\n",
    "    for v in range(0, n):\n",
    "        if a[v] <= b[v]:\n",
    "            list1.append(v)\n",
    "        else: \n",
    "            list2.append(v)\n",
    "    for v in range(0, len(y_test)):\n",
    "        if result2[v] in list1:\n",
    "            result2[v] = 0\n",
    "        elif result2[v] in list2:\n",
    "            result2[v] = 1\n",
    "        else:\n",
    "            print(\"-1\")\n",
    "\n",
    "    print(classification_report(y_test, result2))\n",
    "    print(f\"Accuracy score: {accuracy_score(y_test, result2)}\")\n",
    "    print(f\"Confusion matrix (normalized):\\n{confusion_matrix(y_test, result2, normalize=\"true\")}\")\n",
    "    print(f\"Confusion matrix:\\n{confusion_matrix(y_test, result2)}\")\n",
    "\n",
    "# Default hyper-parameters for initial results (no optimization)\n",
    "cl_kmeans(X_train, X_test, y_train, y_test, n=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyper-parameter optimization (BO-GP)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from skopt.space import Integer\n",
    "# from skopt.utils import use_named_args\n",
    "# from skopt import gp_minimize\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# import time\n",
    "\n",
    "# search_space = [\n",
    "#     Integer(2, 50, name=\"n_clusters\"),\n",
    "#     ]\n",
    "\n",
    "\n",
    "# @use_named_args(search_space)\n",
    "# def objective(**params):\n",
    "#     km_cluster = MiniBatchKMeans(batch_size=100, random_state=42, **params)\n",
    "#     n = params[\"n_clusters\"]\n",
    "\n",
    "#     result = km_cluster.fit_predict(X_train)\n",
    "#     result2 = km_cluster.predict(X_test)\n",
    "\n",
    "#     a = np.zeros(n)\n",
    "#     b = np.zeros(n)\n",
    "#     for v in range(0, n):\n",
    "#         for i in range(0, len(y_train)):\n",
    "#             if result[i] == v:\n",
    "#                 if y_train[i] == 1:\n",
    "#                     a[v] = a[v] + 1\n",
    "#                 else:\n",
    "#                     b[v] = b[v] + 1\n",
    "#     list1 = []\n",
    "#     list2 = []\n",
    "#     for v in range(0, n):\n",
    "#         if a[v] <= b[v]:\n",
    "#             list1.append(v)\n",
    "#         else:\n",
    "#             list2.append(v)\n",
    "#     for v in range(0, len(y_test)):\n",
    "#         if result2[v] in list1:\n",
    "#             result2[v] = 0\n",
    "#         elif result2[v] in list2:\n",
    "#             result2[v] = 1\n",
    "#         else:\n",
    "#             print(\"-1\")\n",
    "\n",
    "#     acc = accuracy_score(y_test, result2)\n",
    "#     print(f\"n_clusters: {n} --> accuracy score: {acc}\")\n",
    "#     return 1 - acc\n",
    "\n",
    "\n",
    "# t1 = time.time()\n",
    "# res_gp = gp_minimize(objective, search_space, n_calls=20)\n",
    "# t2 = time.time()\n",
    "# print(f\"\\nTime taken: {t2-t1} seconds\")\n",
    "# print(f\"Best score: {1-res_gp.fun}\")\n",
    "# print(f\"Best parameters: n_clusters={res_gp.x[0]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "year3project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
